<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>001-torch normal used function | ✨✨✨ WLB! WLB! WLB! ✨✨✨😶‍🌫️</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="1234567891011121314151617## 1. 卷积层### &#96;torch.nn.Conv2d&#96;二维卷积层  输入的尺度是&#96;(N, Cin, H, W)&#96;，输出尺度&#96;(N, Cout, Hout, Wout)&#96;&#96;&#96;&#96;pythonnn.Conv2d(    in_channels,     out_channels,     kernel_size,     stride&#x3D;1,">
<meta property="og:type" content="article">
<meta property="og:title" content="001-torch normal used function">
<meta property="og:url" content="http://example.com/2021/01/11/python_doc/pytorch/001-torch-normal-used-function/index.html">
<meta property="og:site_name" content="✨✨✨ WLB! WLB! WLB! ✨✨✨😶‍🌫️">
<meta property="og:description" content="1234567891011121314151617## 1. 卷积层### &#96;torch.nn.Conv2d&#96;二维卷积层  输入的尺度是&#96;(N, Cin, H, W)&#96;，输出尺度&#96;(N, Cout, Hout, Wout)&#96;&#96;&#96;&#96;pythonnn.Conv2d(    in_channels,     out_channels,     kernel_size,     stride&#x3D;1,">
<meta property="og:locale">
<meta property="article:published_time" content="2021-01-11T08:59:22.000Z">
<meta property="article:modified_time" content="2025-06-09T17:46:47.488Z">
<meta property="article:author" content="EvelynUU">
<meta property="article:tag" content="Pytorch">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="✨✨✨ WLB! WLB! WLB! ✨✨✨😶‍🌫️" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">✨✨✨ WLB! WLB! WLB! ✨✨✨😶‍🌫️</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">重要的事情说三遍</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Suche"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-python_doc/pytorch/001-torch-normal-used-function" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/01/11/python_doc/pytorch/001-torch-normal-used-function/" class="article-date">
  <time class="dt-published" datetime="2021-01-11T08:59:22.000Z" itemprop="datePublished">2021-01-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Pytorch/">Pytorch</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      001-torch normal used function
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">## 1. 卷积层</span></span><br><span class="line"></span><br><span class="line"><span class="section">### `torch.nn.Conv2d`</span></span><br><span class="line">二维卷积层  </span><br><span class="line">输入的尺度是<span class="code">`(N, Cin, H, W)`</span>，输出尺度<span class="code">`(N, Cout, Hout, Wout)`</span></span><br><span class="line"></span><br><span class="line"><span class="code">```python</span></span><br><span class="line"><span class="code">nn.Conv2d(</span></span><br><span class="line"><span class="code">    in_channels, </span></span><br><span class="line"><span class="code">    out_channels, </span></span><br><span class="line"><span class="code">    kernel_size, </span></span><br><span class="line"><span class="code">    stride=1, </span></span><br><span class="line"><span class="code">    padding=0, </span></span><br><span class="line"><span class="code">    dilation=1, </span></span><br><span class="line"><span class="code">    groups=1, </span></span><br><span class="line"><span class="code">    bias=True</span></span><br><span class="line"><span class="code">)</span></span><br></pre></td></tr></table></figure>

<p><strong>Parameters:</strong></p>
<ul>
<li><code>in_channels</code> (int) - 输入信号的通道数</li>
<li><code>out_channels</code> (int) - 卷积产生的通道数</li>
<li><code>kernel_size</code> (int or tuple) - 卷积核的尺寸</li>
<li><code>stride</code> (int or tuple, optional) - 卷积步长，默认为1</li>
<li><code>padding</code> (int or tuple, optional) - 输入的每一条边补充0的层数，默认为0</li>
<li><code>dilation</code> (int or tuple, optional) - 卷积核元素之间的间距，默认为1</li>
<li><code>groups</code> (int, optional) - 从输入通道到输出通道的阻塞连接数，默认为1</li>
<li><code>bias</code> (bool, optional) - 如果bias&#x3D;True，添加可学习的偏置到输出中</li>
</ul>
<hr>
<h3 id="torch-nn-ConvTranspose2d"><a href="#torch-nn-ConvTranspose2d" class="headerlink" title="torch.nn.ConvTranspose2d"></a><code>torch.nn.ConvTranspose2d</code></h3><p>对由多个输入平面组成的输入图像应用二维转置卷积操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">nn.ConvTranspose2d(</span><br><span class="line">    in_channels, </span><br><span class="line">    out_channels, </span><br><span class="line">    kernel_size, </span><br><span class="line">    stride=<span class="number">1</span>, </span><br><span class="line">    padding=<span class="number">0</span>, </span><br><span class="line">    output_padding=<span class="number">0</span>, </span><br><span class="line">    groups=<span class="number">1</span>, </span><br><span class="line">    bias=<span class="literal">True</span>, </span><br><span class="line">    dilation=<span class="number">1</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>Parameters:</strong></p>
<ul>
<li><code>in_channels</code> (int) - 输入信号的通道数</li>
<li><code>out_channels</code> (int) - 卷积产生的通道数</li>
<li><code>kernel_size</code> (int or tuple) - 卷积核的大小</li>
<li><code>stride</code> (int or tuple, optional) - 卷积步长</li>
<li><code>padding</code> (int or tuple, optional) - 输入的每一条边补充<code>padding = kernel - 1 - padding</code>，即<code>(kernel_size - 1)/2</code>个0的层数</li>
<li><code>output_padding</code> (int or tuple, optional) - 在输出的每一个维度的一边补充0的层数</li>
<li><code>dilation</code> (int or tuple, optional) - 卷积核元素之间的间距</li>
<li><code>groups</code> (int, optional) - 从输入通道到输出通道的阻塞连接数</li>
<li><code>bias</code> (bool, optional) - 如果bias&#x3D;True，添加偏置</li>
</ul>
<hr>
<h2 id="torch-utils-data-DataLoader"><a href="#torch-utils-data-DataLoader" class="headerlink" title="torch.utils.data.DataLoader"></a><code>torch.utils.data.DataLoader</code></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">torch.utils.data.DataLoader(</span><br><span class="line">    dataset,</span><br><span class="line">    batch_size=<span class="number">1</span>,</span><br><span class="line">    shuffle=<span class="literal">False</span>,</span><br><span class="line">    sampler=<span class="literal">None</span>,</span><br><span class="line">    batch_sampler=<span class="literal">None</span>,</span><br><span class="line">    num_workers=<span class="number">0</span>,</span><br><span class="line">    collate_fn=<span class="literal">None</span>,</span><br><span class="line">    pin_memory=<span class="literal">False</span>,</span><br><span class="line">    drop_last=<span class="literal">False</span>,</span><br><span class="line">    timeout=<span class="number">0</span>,</span><br><span class="line">    worker_init_fn=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>Parameters:</strong></p>
<ul>
<li><code>dataset</code> (Dataset): 传入的数据集</li>
<li><code>batch_size</code> (int, optional): 每个batch有多少个样本</li>
<li><code>shuffle</code> (bool, optional): 在每个epoch开始的时候，对数据进行重新排序</li>
<li><code>sampler</code> (Sampler, optional): 自定义从数据集中取样本的策略（与shuffle互斥）</li>
<li><code>batch_sampler</code> (Sampler, optional): 与sampler类似，但一次只返回一个batch的indices（与batch_size&#x2F;shuffle&#x2F;sampler互斥）</li>
<li><code>num_workers</code> (int, optional): 处理data loading的进程数（0表示在主进程加载）</li>
<li><code>collate_fn</code> (callable, optional): 将list的sample组成mini-batch的函数</li>
<li><code>pin_memory</code> (bool, optional): 设置为True时会将tensors拷贝到CUDA固定内存中</li>
<li><code>drop_last</code> (bool, optional): 是否丢弃最后一个不完整的batch（默认为False）</li>
<li><code>timeout</code> (numeric, optional): 收集batch的等待时间（&gt;&#x3D;0）</li>
<li><code>worker_init_fn</code> (callable, optional): 每个worker的初始化函数</li>
</ul>
<hr>
<h2 id="Torchvision-Transforms"><a href="#Torchvision-Transforms" class="headerlink" title="Torchvision Transforms"></a>Torchvision Transforms</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean, std)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<ol>
<li><p><strong><code>torchvision.transforms.Compose()</code></strong><br>主要作用是串联多个图片变换的操作</p>
</li>
<li><p><strong><code>torchvision.transforms.ToTensor()</code></strong>  </p>
<ul>
<li>将shape为<code>(H, W, C)</code>的numpy.ndarray或PIL Image转为shape为<code>(C, H, W)</code>的tensor</li>
<li>将数值归一化到[0,1]（直接除以255）</li>
</ul>
</li>
<li><p><strong><code>torchvision.transforms.Normalize()</code></strong><br>对每个通道执行：<code>image = (image - mean) / std</code><br>（ToTensor把0-255变换到0-1，Normalize再把0-1变换到(-1,1)）</p>
</li>
</ol>
<pre><code>
</code></pre>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/01/11/python_doc/pytorch/001-torch-normal-used-function/" data-id="cmbs1b782001m8ssd6zfc94qk" data-title="001-torch normal used function" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/01/12/python_doc/pytorch/002-tensors-basic/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Neuer</strong>
      <div class="article-nav-title">
        
          002-tensors basic
        
      </div>
    </a>
  
  
    <a href="/2021/01/01/index/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Älter</strong>
      <div class="article-nav-title">Welcome to UEvelyn&#39;s blog</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Kategorien</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/CNBC/">CNBC</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/CSS/">CSS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DevOps/">DevOps</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/DevOps/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DevOps/Openshift/">Openshift</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/JavaScript/">JavaScript</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Principles/">Principles</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Pytorch/">Pytorch</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNBC-Finance/" rel="tag">CNBC Finance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CSS/" rel="tag">CSS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/" rel="tag">Docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Javascript/" rel="tag">Javascript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Openshift/" rel="tag">Openshift</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Principles/" rel="tag">Principles</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CNBC-Finance/" style="font-size: 10px;">CNBC Finance</a> <a href="/tags/CSS/" style="font-size: 10px;">CSS</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/Javascript/" style="font-size: 20px;">Javascript</a> <a href="/tags/Openshift/" style="font-size: 10px;">Openshift</a> <a href="/tags/Principles/" style="font-size: 10px;">Principles</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">June 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">February 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">January 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/06/09/css_doc/001-%E5%B8%83%E5%B1%80-%E4%BC%AA%E5%85%83%E7%B4%A0-CSS3%E5%8A%A8%E7%94%BB-%E5%AE%9E%E6%88%98/">001-布局-伪元素-CSS3动画-实战</a>
          </li>
        
          <li>
            <a href="/2025/06/09/others_doc/001-MVC%E4%B8%8EMVVM%E6%9E%B6%E6%9E%84%E5%AF%B9%E6%AF%94/">001-MVC与MVVM架构对比</a>
          </li>
        
          <li>
            <a href="/2025/06/09/others_doc/CNBC%E9%87%91%E8%9E%8D%E6%96%B0%E9%97%BB%E7%B2%BE%E5%90%AC-1/">CNBC金融新闻精听</a>
          </li>
        
          <li>
            <a href="/2025/06/09/devops_doc/001-OpenShift-Web%E6%8E%A7%E5%88%B6%E5%8F%B0%E9%83%A8%E7%BD%B2%E8%BF%90%E7%BB%B4%E6%80%BB%E7%BB%93/">001-OpenShift Web控制台部署运维总结</a>
          </li>
        
          <li>
            <a href="/2025/06/09/javascript_doc/014-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3/">014-垃圾回收机制详解</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 EvelynUU<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>